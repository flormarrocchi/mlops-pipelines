{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c2812a-02ee-4e74-b1aa-2dbce62fed60",
   "metadata": {},
   "source": [
    "# AutoMLOps Pipeline - Using Kubeflow components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cdaa99-545a-4b7c-8fa7-8a02522ae3f3",
   "metadata": {},
   "source": [
    "## Setup Git\n",
    "Prerequisite for use of AutoMLOps.deploy() with use_ci=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea103cf-d70a-4022-9fe3-a1965d7462bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --global user.email 'user@github.com'\n",
    "! git config --global user.name 'username'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a46db-bdd2-41c0-b7a3-c014a9efabd1",
   "metadata": {},
   "source": [
    "# Install AutoMLOps\n",
    "\n",
    "Install AutoMLOps from [PyPI](https://pypi.org/project/google-cloud-automlops/), or locally by cloning the repo and running `pip install .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a22f2f-ea4c-4efc-9bee-943540c9537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install google-cloud-automlops --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abfe5-f5b0-4af9-9c9a-eac7b32566eb",
   "metadata": {},
   "source": [
    "# Restart the kernel\n",
    "Once you've installed the AutoMLOps package, you need to restart the notebook kernel so it can find the package.\n",
    "\n",
    "**Note: Once this cell has finished running, continue on. You do not need to re-run any of the cells above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f9858df-6a9f-43c0-a86a-d0e457004099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv('IS_TESTING'):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031fbab8-70c6-4bb5-8af3-e76f1a9a4e39",
   "metadata": {},
   "source": [
    "### Install additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02168d1c-429e-4afe-8cb9-dd5945dfa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 'kfp<2' \\\n",
    "                                 'google-cloud-pipeline-components<2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543231f1-9b40-4aa2-aaa3-ed21739d2c9e",
   "metadata": {},
   "source": [
    "### Check the package versions\n",
    "Check the versions of the packages you installed. The KFP SDK version should be >=1.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197071ca-10eb-4a3f-a231-3497189a9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.22\n",
      "google_cloud_pipeline_components version: 1.0.44\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941bc2e-811c-485f-b4d8-56d9ac8894fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set your project ID\n",
    "Set your project ID below. If you don't know your project ID, leave the field blank and the following cells may be able to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cc6889-16ad-4764-84cb-f122d02864e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'project-id'  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1938115-4a30-427d-b933-1486385d27aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5bdb8-8e54-482e-b163-2d707629a27f",
   "metadata": {},
   "source": [
    "### Create a Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fbce68-dd33-4eb3-a432-bc438e46c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://bucket-uri\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef184e-f633-4410-9f67-d41dd20d34de",
   "metadata": {},
   "source": [
    "### Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae0c584-fa8d-438f-839f-a7d4d791aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af700057-c818-4be7-b788-f2e7375e1e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Account: 662741782935-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    shell_output = !gcloud auth list 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614dbd3d-189e-4251-bc14-bec0db8f157d",
   "metadata": {},
   "source": [
    "#### Set service account access for Vertex AI Pipelines\n",
    "\n",
    "Run the following commands to grant service account access to read and write pipeline artifacts in the bucket that is created in the previous step -- only need to run these once per service account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc37b21-4b8d-4f5b-8320-0affec2ff11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes made to gs://fmcc-custom-ml-experiments/\n",
      "No changes made to gs://fmcc-custom-ml-experiments/\n"
     ]
    }
   ],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296eccc1-47af-41bb-9a70-54def63e1f0d",
   "metadata": {},
   "source": [
    "### Import AutoMLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f5ca60-951b-414d-9523-5eaba11b45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_automlops import AutoMLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a8aff-6894-4cec-bc74-030a16a0ceda",
   "metadata": {},
   "source": [
    "### Others imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04494ae0-d48f-4922-aecf-0f4b66d9e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact, ClassificationMetrics, Input, Metrics,\n",
    "                        Output, component, Dataset, Model, HTML, Markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ac10a-6068-49f8-9ff6-e57e07cb7315",
   "metadata": {},
   "source": [
    "## Clear the cache\n",
    "`AutoMLOps.clear_cache` will remove previous instantiations of AutoMLOps components and pipelines. Use this function if you have previously defined a component that you no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3da2f9b-eb87-42ee-ad2a-e85397c6f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache cleared.\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf29dc-60c5-461b-984d-e8ee4e41d9a2",
   "metadata": {
    "id": "aip_constants:endpoint"
   },
   "source": [
    "#### Vertex AI constants\n",
    "\n",
    "Setup up the following constants for Vertex AI Pipeline:\n",
    "- `PIPELINE_NAME`: Set name for the Pipeline.\n",
    "- `PIPELINE_ROOT`: Cloud Storage bucket path to store pipeline artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77a5e0b4-6e44-4fc2-8b2b-d83f18daae91",
   "metadata": {
    "id": "aip_constants:endpoint"
   },
   "outputs": [],
   "source": [
    "# set path for storing the pipeline artifacts\n",
    "PIPELINE_NAME = \"automlops-pipeline\"\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/beans\".format(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547ad6f-538c-4023-abd5-6d733caa9934",
   "metadata": {},
   "source": [
    "## Define Kubeflow custom components\n",
    "You must specify the output_component_file with the name of your component. For AutoMLOps to know where to find the Kubeflow component spec, set this variable to the following string f\"{AutoMLOps.OUTPUT_DIR}/your_component_name.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35ad0405-bc1e-4300-891c-da2509cba0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"scorecardpy==0.1.9.6\"],\n",
    "    output_component_file = f'{AutoMLOps.OUTPUT_DIR}/credit_score_dataset.yaml'\n",
    ")\n",
    "def credit_score_dataset(\n",
    "    project_id: str,\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    "):\n",
    "    import pandas as pd\n",
    "    import scorecardpy as sc\n",
    "\n",
    "    import logging\n",
    "\n",
    "    # load germancredit data\n",
    "    data = sc.germancredit()\n",
    "\n",
    "    # filter variable via missing rate, iv, identical value rate\n",
    "    dt_s = sc.var_filter(data, y=\"creditability\")\n",
    "\n",
    "    # breaking dt into train and test\n",
    "    train, test = sc.split_df(dt_s, 'creditability').values()\n",
    "    \n",
    "    # woe binning ------\n",
    "    bins = sc.woebin(dt_s, y=\"creditability\")\n",
    "    # sc.woebin_plot(bins)\n",
    "\n",
    "    # binning adjustment\n",
    "    breaks_adj = {\n",
    "        'age.in.years': [26, 35, 40],\n",
    "        'other.debtors.or.guarantors': [\"none\", \"co-applicant%,%guarantor\"]\n",
    "    }\n",
    "    bins_adj = sc.woebin(dt_s, y=\"creditability\", breaks_list=breaks_adj)\n",
    "    \n",
    "    # converting train and test into woe values\n",
    "    train_woe = sc.woebin_ply(train, bins_adj)\n",
    "    test_woe = sc.woebin_ply(test, bins_adj)\n",
    "\n",
    "    train_woe.to_csv(dataset_train.path, index=False)\n",
    "    test_woe.to_csv(dataset_test.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a89fb67b-cc68-42c9-8736-a92d35de23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"scorecardpy==0.1.9.6\"],\n",
    "    output_component_file = f'{AutoMLOps.OUTPUT_DIR}/model_train.yaml'\n",
    ")\n",
    "def model_train(\n",
    "    dataset: Input[Dataset],\n",
    "    model: Output[Artifact],\n",
    "):\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    train_woe = pd.read_csv(dataset.path)\n",
    "    y_train = train_woe.loc[:,'creditability']\n",
    "    X_train = train_woe.loc[:,train_woe.columns != 'creditability']\n",
    "\n",
    "    model_pipeline =  LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1, random_state=42)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    model.metadata[\"framework\"] = \"scikit-learn\"\n",
    "    model.metadata[\"containerSpec\"] = {\n",
    "        \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\"\n",
    "    }\n",
    "\n",
    "    file_name = model.path + \"/model.pkl\"\n",
    "    import pathlib\n",
    "\n",
    "    pathlib.Path(model.path).mkdir()\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        pickle.dump(model_pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41b846d9-afc1-4316-b8b9-a8b7c0b243af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"scorecardpy==0.1.9.6\"],\n",
    "    output_component_file = f'{AutoMLOps.OUTPUT_DIR}/model_evaluate_metric.yaml'\n",
    ")\n",
    "def model_evaluate_metric(\n",
    "    test_set: Input[Dataset],\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics],\n",
    ") -> dict:\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from sklearn.metrics import (roc_curve,\n",
    "                                 confusion_matrix,\n",
    "                                 accuracy_score,\n",
    "                                 precision_score,\n",
    "                                 recall_score,\n",
    "                                 f1_score,\n",
    "                                 log_loss,\n",
    "                                 roc_auc_score,\n",
    "                                 average_precision_score)\n",
    "    \n",
    "    data = pd.read_csv(test_set.path)\n",
    "    file_name = model.path + \"/model.pkl\"\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        model_pipeline = pickle.load(file)\n",
    "    \n",
    "    X=data.drop(columns=['creditability'])\n",
    "    y=data.creditability\n",
    "\n",
    "    y_pred = model_pipeline.predict(X)\n",
    "\n",
    "    y_scores = model_pipeline.predict_proba(X)[:, 1]\n",
    "    \n",
    "    metrics.log_metric('Framework', 'scikit-learn')\n",
    "    metrics.log_metric('Threshold','0.5000')\n",
    "    metrics.log_metric('Precision', precision_score(y, y_pred))\n",
    "    metrics.log_metric('Recall', recall_score(y, y_pred))\n",
    "    metrics.log_metric('Accuracy', accuracy_score(y, y_pred))\n",
    "    metrics.log_metric('F1 score', f1_score(y, y_pred))\n",
    "    metrics.log_metric('Log loss', log_loss(y, y_pred))\n",
    "    metrics.log_metric('ROC AUC', roc_auc_score(y, y_scores))\n",
    "    metrics.log_metric('ROC PR', average_precision_score(y, y_scores))\n",
    "    \n",
    "    output = {'auROC': roc_auc_score(y, y_pred)}\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ded9d-9201-4cd5-8b70-c836e38ccbdc",
   "metadata": {
    "id": "define_pipeline:gcpc,beans,lcn"
   },
   "source": [
    "## Define pipeline \n",
    "Define your pipeline. You can optionally give the pipeline a name and description. Define the structure by listing the components to be called in your pipeline; use .after to specify the order of execution.\n",
    "We will define a pipeline for AutoML tabular classification using the components from `google_cloud_pipeline_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fe50dea-6696-4bc1-8965-0549767270cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@AutoMLOps.pipeline(name=\"automlops-pipeline\")\n",
    "def pipeline(project: str,\n",
    "             location: str,\n",
    "             UUID: str\n",
    "            ):\n",
    "    from google_cloud_pipeline_components.v1.endpoint import EndpointCreateOp, ModelDeployOp\n",
    "    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "    from google_cloud_pipeline_components.experimental.custom_job.utils import (\n",
    "        create_custom_training_job_op_from_component,\n",
    "    )\n",
    "    \n",
    "    data_op = credit_score_dataset(project_id=project)\n",
    "\n",
    "    custom_job_distributed_training_op = create_custom_training_job_op_from_component(\n",
    "        model_train,\n",
    "        replica_count=1\n",
    "    )\n",
    "\n",
    "    model_train_op = custom_job_distributed_training_op(\n",
    "        dataset=data_op.outputs[\"dataset_train\"],\n",
    "        project=project,\n",
    "        location=location,\n",
    "    ).after(data_op)\n",
    "\n",
    "    model_evaluate_metric_op = model_evaluate_metric(\n",
    "        test_set=data_op.outputs[\"dataset_test\"],\n",
    "        model=model_train_op.outputs[\"model\"],\n",
    "    ).after(model_train_op)\n",
    "    \n",
    "    # shapely parameters\n",
    "    parameters = {\"sampled_shapley_attribution\": {\"path_count\": 10}}\n",
    "    \n",
    "    # Explanation metadata\n",
    "    COLUMNS = ['purpose_woe', 'installment_rate_in_percentage_of_disposable_income_woe', 'status_of_existing_checking_account_woe', 'housing_woe', 'credit_history_woe', 'savings_account_and_bonds_woe', 'duration_in_month_woe', 'present_employment_since_woe', 'age_in_years_woe', 'other_debtors_or_guarantors_woe', 'other_installment_plans_woe', 'property_woe', 'credit_amount_woe']\n",
    "\n",
    "    metadata = {\n",
    "    \"inputs\":{\n",
    "        \"features\": {\"index_feature_mapping\": COLUMNS, \"encoding\": \"BAG_OF_FEATURES\"}\n",
    "    },\n",
    "    \"outputs\":{\"creditability\": {}}}\n",
    "\n",
    "    model_upload_op = ModelUploadOp(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=f\"german-credit-scroe-model-{UUID}\",\n",
    "        unmanaged_container_model=model_train_op.outputs[\"model\"],\n",
    "        explanation_parameters=parameters,\n",
    "        explanation_metadata=metadata,\n",
    "    ).after(model_train_op)\n",
    "\n",
    "    endpoint_create_op = EndpointCreateOp(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=f\"german-credit-scroe-endpoint-{UUID}\",\n",
    "    )\n",
    "\n",
    "    ModelDeployOp(\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=f\"german-credit-scroe-model-{UUID}\",\n",
    "        dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "    ).after(model_upload_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b5d78-5c44-44db-a8c0-ade1cdb58be2",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "#### UUID\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7497e5e3-cfc4-44ad-9133-9e1378f76295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2igzh819'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()\n",
    "UUID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a5fcc-f44b-4186-82c7-95b1a13d638b",
   "metadata": {},
   "source": [
    "## Define the Pipeline Arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41f8900f-8379-4808-bfa9-36b8733a2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"location\": REGION,\n",
    "    \"UUID\": UUID,\n",
    "    #\"vertex_experiment_tracking_name\": \"mlops-experiment-name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e4e367-cb18-413c-aaea-93bd38f32da8",
   "metadata": {},
   "source": [
    "## Generate and Run the pipeline\n",
    "### AutoMLOps.generate(...) generates the MLOps codebase. Users can specify the tooling and technologies they would like to use in their MLOps pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caf1b0c6-4f6c-46de-a1c5-333afedc4c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing directories under AutoMLOps/\n",
      "Writing configurations to AutoMLOps/configs/defaults.yaml\n",
      "Writing README.md to AutoMLOps/README.md\n",
      "Writing kubeflow pipelines code to AutoMLOps/pipelines, AutoMLOps/components\n",
      "Writing scripts to AutoMLOps/scripts\n",
      "Writing submission service code to AutoMLOps/services\n",
      "Writing gcloud provisioning code to AutoMLOps/provision\n",
      "Writing cloud build config to AutoMLOps/cloudbuild.yaml\n",
      "Code Generation Complete.\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.generate(project_id=PROJECT_ID,\n",
    "                   pipeline_params=pipeline_params,\n",
    "                   use_ci=True,\n",
    "                   naming_prefix=\"automlops-kfp\",\n",
    "                   schedule_pattern='59 11 * * 0' # retrain every Sunday at Midnight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407e0d2-deba-415f-ba89-0fbc50dfaa41",
   "metadata": {},
   "source": [
    "### AutoMLOps.provision(...) runs provisioning scripts to create and maintain necessary infra for MLOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5535cfdc-c123-4f57-9328-c6237cf67471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Provisioning requires these permissions:\n",
      "-iam.serviceAccounts.actAs\n",
      "-storage.buckets.create\n",
      "-artifactregistry.repositories.list\n",
      "-pubsub.topics.list\n",
      "-cloudbuild.builds.list\n",
      "-pubsub.subscriptions.create\n",
      "-cloudfunctions.functions.create\n",
      "-cloudbuild.builds.create\n",
      "-cloudscheduler.jobs.create\n",
      "-artifactregistry.repositories.create\n",
      "-serviceusage.services.enable\n",
      "-source.repos.create\n",
      "-pubsub.subscriptions.list\n",
      "-pubsub.topics.create\n",
      "-iam.serviceAccounts.create\n",
      "-cloudfunctions.functions.get\n",
      "-cloudscheduler.jobs.list\n",
      "-serviceusage.services.use\n",
      "-resourcemanager.projects.setIamPolicy\n",
      "-source.repos.list\n",
      "-storage.buckets.get\n",
      "-iam.serviceAccounts.list\n",
      "\n",
      "You are currently using: keshv@google.com. Please check your account permissions.\n",
      "The following are the recommended roles for provisioning:\n",
      "-roles/cloudscheduler.admin\n",
      "-roles/serviceusage.serviceUsageAdmin\n",
      "-roles/cloudfunctions.admin\n",
      "-roles/resourcemanager.projectIamAdmin\n",
      "-roles/storage.admin\n",
      "-roles/source.admin\n",
      "-roles/pubsub.editor\n",
      "-roles/cloudbuild.builds.editor\n",
      "-roles/iam.serviceAccountAdmin\n",
      "-roles/artifactregistry.admin\n",
      "-roles/iam.serviceAccountUser\n",
      "\n",
      "\u001b[0;32m Setting up API services in project fmcc-mlops \u001b[0m\n",
      "Operation \"operations/acat.p2-662741782935-122838e6-eb1c-44fc-8214-9e49f6de6dc5\" finished successfully.\n",
      "\u001b[0;32m Setting up Artifact Registry in project fmcc-mlops \u001b[0m\n",
      "Listing items under project fmcc-mlops, location us-central1.\n",
      "\n",
      "automlops-kfp-artifact-registry        DOCKER  STANDARD_REPOSITORY  Artifact Registry automlops-kfp-artifact-registry in us-central1.        us-central1          Google-managed key  2023-10-02T12:08:05  2023-10-02T14:32:23  2875.587\n",
      "Artifact Registry: automlops-kfp-artifact-registry already exists in project fmcc-mlops\n",
      "\u001b[0;32m Setting up Storage Bucket in project fmcc-mlops \u001b[0m\n",
      "gs://fmcc-mlops-automlops-kfp-bucket/\n",
      "GS Bucket: fmcc-mlops-automlops-kfp-bucket already exists in project fmcc-mlops\n",
      "\u001b[0;32m Setting up Pipeline Job Runner Service Account in project fmcc-mlops \u001b[0m\n",
      "Pipeline Runner Service Account         vertex-pipelines@fmcc-mlops.iam.gserviceaccount.com  False\n",
      "Service Account: vertex-pipelines already exists in project fmcc-mlops\n",
      "\u001b[0;32m Setting up IAM roles for Pipeline Job Runner Service Account in project fmcc-mlops \u001b[0m\n",
      "\u001b[0;32m Setting up Cloud Source Repository in project fmcc-mlops \u001b[0m\n",
      "automlops-kfp-repository        fmcc-mlops  https://source.developers.google.com/p/fmcc-mlops/r/automlops-kfp-repository\n",
      "Cloud Source Repository: automlops-kfp-repository already exists in project fmcc-mlops\n",
      "\u001b[0;32m Setting up Queueing Service in project fmcc-mlops \u001b[0m\n",
      "name: projects/fmcc-mlops/topics/automlops-kfp-queueing-svc\n",
      "Pub/Sub Topic: automlops-kfp-queueing-svc already exists in project fmcc-mlops\n",
      "\u001b[0;32m Deploying Cloud Functions: automlops-kfp-job-submission-svc in project fmcc-mlops \u001b[0m\n",
      "WARNING: Effective May 15, 2023, Container Registry (used by default by Cloud Functions 1st gen for storing build artifacts) is deprecated: https://cloud.google.com/artifact-registry/docs/transition/transition-from-gcr. Artifact Registry is the recommended successor that you can use by adding the '--docker_registry=artifact-registry' flag.\n",
      "\n",
      "Deploying function (may take a while - up to 2 minutes)...\n",
      "..\n",
      "For Cloud Build Logs, visit: https://console.cloud.google.com/cloud-build/builds;region=us-central1/8e53dc51-8234-4cc4-a38a-563e27cdd896?project=662741782935\n",
      "...................................done.\n",
      "availableMemoryMb: 512\n",
      "buildId: 8e53dc51-8234-4cc4-a38a-563e27cdd896\n",
      "buildName: projects/662741782935/locations/us-central1/builds/8e53dc51-8234-4cc4-a38a-563e27cdd896\n",
      "dockerRegistry: CONTAINER_REGISTRY\n",
      "entryPoint: process_request\n",
      "eventTrigger:\n",
      "  eventType: google.pubsub.topic.publish\n",
      "  failurePolicy: {}\n",
      "  resource: projects/fmcc-mlops/topics/automlops-kfp-queueing-svc\n",
      "  service: pubsub.googleapis.com\n",
      "ingressSettings: ALLOW_ALL\n",
      "labels:\n",
      "  deployment-tool: cli-gcloud\n",
      "maxInstances: 3000\n",
      "name: projects/fmcc-mlops/locations/us-central1/functions/automlops-kfp-job-submission-svc\n",
      "runtime: python39\n",
      "serviceAccountEmail: vertex-pipelines@fmcc-mlops.iam.gserviceaccount.com\n",
      "sourceUploadUrl: https://storage.googleapis.com/uploads-505801734809.us-central1.cloudfunctions.appspot.com/3c2a68fb-7b82-4f50-a357-a150a392b65d.zip\n",
      "status: ACTIVE\n",
      "timeout: 540s\n",
      "updateTime: '2023-10-02T14:39:25.169Z'\n",
      "versionId: '13'\n",
      "\u001b[0;32m Setting up Cloud Build Trigger in project fmcc-mlops \u001b[0m\n",
      "name: automlops-kfp-build-trigger\n",
      "Cloudbuild Trigger already exists in project fmcc-mlops for repo automlops-kfp-repository\n",
      "\u001b[0;32m Setting up Cloud Scheduler Job in project fmcc-mlops \u001b[0m\n",
      "automlops-kfp-schedule        us-central1  59 11 * * 0 (Etc/UTC)  Pub/Sub      ENABLED\n",
      "Cloud Scheduler Job: automlops-kfp-schedule already exists in project fmcc-mlops\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.provision(hide_warnings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa082ba-5f16-47f6-886e-1b0afcc95ae3",
   "metadata": {},
   "source": [
    "AutoMLOps.deploy(...) builds and pushes component container, then triggers the pipeline job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35c0a4c7-2479-4c78-8ac2-b161e08182da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Running precheck for deploying requires these permissions:\n",
      "-serviceusage.services.get\n",
      "-iam.serviceAccounts.get\n",
      "-cloudbuild.builds.get\n",
      "-artifactregistry.repositories.get\n",
      "-cloudfunctions.functions.get\n",
      "-source.repos.update\n",
      "-storage.buckets.update\n",
      "-pubsub.topics.get\n",
      "-resourcemanager.projects.getIamPolicy\n",
      "-pubsub.subscriptions.get\n",
      "\n",
      "You are currently using: keshv@google.com. Please check your account permissions.\n",
      "The following are the recommended roles for deploying with precheck:\n",
      "-roles/source.writer\n",
      "-roles/artifactregistry.reader\n",
      "-roles/serviceusage.serviceUsageViewer\n",
      "-roles/storage.admin\n",
      "-roles/iam.roleViewer\n",
      "-roles/cloudbuild.builds.editor\n",
      "-roles/cloudfunctions.viewer\n",
      "-roles/iam.serviceAccountUser\n",
      "-roles/pubsub.viewer\n",
      "\n",
      "Checking for required API services in project fmcc-mlops...\n",
      "Checking for Artifact Registry in project fmcc-mlops...\n",
      "Checking for Storage Bucket in project fmcc-mlops...\n",
      "Checking for Pipeline Runner Service Account in project fmcc-mlops...\n",
      "Checking for IAM roles on Pipeline Runner Service Account in project fmcc-mlops...\n",
      "Checking for Cloud Source Repo in project fmcc-mlops...\n",
      "Checking for Pub/Sub Topic in project fmcc-mlops...\n",
      "Checking for Pub/Sub Subscription in project fmcc-mlops...\n",
      "Checking for Cloud Functions Pipeline Job Submission Service in project fmcc-mlops...\n",
      "Checking for Cloud Build Trigger in project fmcc-mlops...\n",
      "Precheck successfully completed, continuing to deployment.\n",
      "\n",
      "[automlops d7db719] Run AutoMLOps\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n",
      "remote: Waiting for private key checker: 3/3 objects left        \n",
      "To https://source.developers.google.com/p/fmcc-mlops/r/automlops-kfp-repository\n",
      "   0448b23..d7db719  automlops -> automlops\n",
      "Pushing code to automlops branch, triggering build...\n",
      "Cloud Build job running at: https://console.cloud.google.com/cloud-build/builds;region=us-central1\n",
      "Please wait for this build job to complete.\n",
      "\n",
      "#################################################################\n",
      "#                                                               #\n",
      "#                       RESOURCES MANIFEST                      #\n",
      "#---------------------------------------------------------------#\n",
      "#     Generated resources can be found at the following urls    #\n",
      "#                                                               #\n",
      "#################################################################\n",
      "\n",
      "Google Cloud Storage Bucket: https://console.cloud.google.com/storage/fmcc-mlops-automlops-kfp-bucket\n",
      "Artifact Registry: https://console.cloud.google.com/artifacts/docker/fmcc-mlops/us-central1/automlops-kfp-artifact-registry\n",
      "Service Accounts: https://console.cloud.google.com/iam-admin/serviceaccounts?project=fmcc-mlops\n",
      "APIs: https://console.cloud.google.com/apis\n",
      "Cloud Source Repository: https://source.cloud.google.com/fmcc-mlops/automlops-kfp-repository/+/automlops:\n",
      "Cloud Build Jobs: https://console.cloud.google.com/cloud-build/builds;region=us-central1\n",
      "Vertex AI Pipeline Runs: https://console.cloud.google.com/vertex-ai/pipelines/runs\n",
      "Cloud Build Trigger: https://console.cloud.google.com/cloud-build/triggers;region=us-central1\n",
      "Pipeline Job Submission Service (Cloud Functions): https://console.cloud.google.com/functions/details/us-central1/automlops-kfp-job-submission-svc\n",
      "Pub/Sub Queueing Service Topic: https://console.cloud.google.com/cloudpubsub/topic/detail/automlops-kfp-queueing-svc\n",
      "Pub/Sub Queueing Service Subscriptions: https://console.cloud.google.com/cloudpubsub/subscription/list\n",
      "Cloud Scheduler Job: https://console.cloud.google.com/cloudscheduler\n"
     ]
    }
   ],
   "source": [
    "AutoMLOps.deploy(precheck=True,                     # precheck is optional, defaults to True\n",
    "                 hide_warnings=False)               # hide_warnings is optional, defaults to True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5e553-65a7-429b-a7e4-301cbb60e11f",
   "metadata": {},
   "source": [
    "### AutoMLOps.deprovision(...): Runs provisioning scripts to tear down MLOps infra created using AutoMLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009bd534-e548-49cf-bd9d-c1aefda00267",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoMLOps.deprovision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73270cd-0d34-4ef3-9847-bccb91eb1a12",
   "metadata": {},
   "source": [
    "### AutoMLOps.launchAll(...): Runs \"generate()\", \"provision()\" and \"deploy()\" all in succession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02299570-df12-496b-a84f-1600b59971f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoMLOps.launchAll(\n",
    "    project_id=PROJECT_ID,\n",
    "    pipeline_params=pipeline_params,\n",
    "    use_ci=True,\n",
    "    naming_prefix=\"automlops-kfp\",\n",
    "    schedule_pattern='59 11 * * 0' # retrain every Sunday at Midnight\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
